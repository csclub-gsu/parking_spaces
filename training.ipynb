{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e03658a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c44df27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 903 files belonging to 2 classes.\n",
      "Using 723 files for training.\n",
      "Found 903 files belonging to 2 classes.\n",
      "Using 180 files for validation.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"training_data/\"\n",
    "\n",
    "#Resize data and set batches for processing\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "#spliting the data for training/validation\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    #Loading the training set\n",
    "    data_dir,\n",
    "    #The .2 reserves 20% of the dataset to be used for validiation, the rest for training\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    #Setting a seed to be able to reproduces\n",
    "    seed=1337,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    #Load the training set\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "#A bunch of blackbox code that has tensorflow run better\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe6c6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a sequential CNN model(go for image processing)\n",
    "model = models.Sequential([\n",
    "    \n",
    "    #adjusting pixel value for better processing\n",
    "    layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    \n",
    "    #Convolution Layer, seperate the img into 3x3(pixels) filters to identify features\n",
    "    #Using a relu(Rectified Linear Activation Function) to adjust for error and adjustments\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    \n",
    "    #improve efficiency by cutting the output\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #Series of layers that take in output of past layers and run through another\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    \n",
    "    #Turn output into array\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    #create layer of nodes\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    \n",
    "    #turn nodes into the classified groups\n",
    "    layers.Dense(2)  # two classes: occupied and empty\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5958fa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 13:27:08.240443: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [723]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-09-05 13:27:08.240628: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [723]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - ETA: 0s - loss: 0.6055 - accuracy: 0.6750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 13:27:15.018728: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [180]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-09-05 13:27:15.019183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [180]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 8s 320ms/step - loss: 0.6055 - accuracy: 0.6750 - val_loss: 0.5256 - val_accuracy: 0.7333\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 18s 816ms/step - loss: 0.4578 - accuracy: 0.6971 - val_loss: 0.4380 - val_accuracy: 0.8111\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 19s 857ms/step - loss: 0.3686 - accuracy: 0.8409 - val_loss: 0.4086 - val_accuracy: 0.8167\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 18s 783ms/step - loss: 0.2234 - accuracy: 0.9336 - val_loss: 0.4733 - val_accuracy: 0.8111\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 18s 797ms/step - loss: 0.0964 - accuracy: 0.9723 - val_loss: 0.4254 - val_accuracy: 0.8389\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 18s 785ms/step - loss: 0.0564 - accuracy: 0.9779 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 19s 823ms/step - loss: 0.1452 - accuracy: 0.9433 - val_loss: 0.6853 - val_accuracy: 0.7333\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 18s 768ms/step - loss: 0.0570 - accuracy: 0.9848 - val_loss: 0.6860 - val_accuracy: 0.8167\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 18s 800ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.7420 - val_accuracy: 0.8111\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 19s 835ms/step - loss: 0.0077 - accuracy: 0.9959 - val_loss: 0.8692 - val_accuracy: 0.7944\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "turning the network into a model, 'adam' algorithm for learing.\n",
    "loss, measures accuracy, SpaceCategoryCrossentropy since to label classes\n",
    "meteric is used for accuracy.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Run the model with the training and validiation dataset, 10 times\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a719b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 - 1s - loss: 0.8692 - accuracy: 0.7944 - 599ms/epoch - 100ms/step\n",
      "\n",
      "Validation accuracy: 0.7944444417953491\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(val_ds, verbose=2)\n",
    "print(\"\\nValidation accuracy:\", val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "effa306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('parking_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d7e2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
