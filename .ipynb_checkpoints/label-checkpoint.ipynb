{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25b31735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import matplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c61db27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_folder = \"raw_images/\"\n",
    "annotated_folder = \"annotated_images/\"\n",
    "\n",
    "occupied_dir = \"training_data/occupied/\"\n",
    "empty_dir = \"training_data/empty/\"\n",
    "\n",
    "if not os.path.exists(occupied_dir):\n",
    "    os.makedirs(occupied_dir)\n",
    "\n",
    "if not os.path.exists(empty_dir):\n",
    "    os.makedirs(empty_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80cd534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_box_color(patch):\n",
    "    center_y, center_x = patch.shape[0] // 2, patch.shape[1] // 2\n",
    "    region = patch[center_y - 1:center_y + 2, center_x - 1:center_x + 2]  # 3x3 region around the center\n",
    "    r, g, b = np.mean(region, axis=(0, 1))\n",
    "    \n",
    "    if 150 < r < 255 and 50 < g < 150 and b < 80:  # Adjusted for orangeish red\n",
    "        return 'red'\n",
    "    if 50 < r < 150 and 50 < g < 150 and 150 < b < 255:  # Adjusted for lapis blue\n",
    "        return 'blue'\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5391449",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m patch \u001b[38;5;241m=\u001b[39m annotated_img[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Check the color of the box. Here we're checking the top-left pixel, but you might want to use more pixels for accuracy\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m color \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_box_color\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m color:\n\u001b[1;32m     26\u001b[0m     raw_patch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(raw_img)[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw]\n",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m, in \u001b[0;36mdetect_box_color\u001b[0;34m(patch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_box_color\u001b[39m(patch):\n\u001b[0;32m----> 2\u001b[0m     center_y, center_x \u001b[38;5;241m=\u001b[39m patch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[43mpatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      3\u001b[0m     region \u001b[38;5;241m=\u001b[39m patch[center_y \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:center_y \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m, center_x \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:center_x \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]  \u001b[38;5;66;03m# 3x3 region around the center\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     r, g, b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(region, axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "for img_name in os.listdir(raw_folder):\n",
    "    # Load raw and annotated images\n",
    "    raw_img = Image.open(os.path.join(raw_folder, img_name))\n",
    "    annotated_img = cv2.imread(os.path.join(annotated_folder, img_name))\n",
    "    \n",
    "    if annotated_img is None:\n",
    "        print(f\"Warning: Unable to load {img_name} from annotated images.\")\n",
    "        continue\n",
    "    \n",
    "    gray = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Use binary thresholding to detect the boxes\n",
    "    _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        patch = annotated_img[y:y+h, x:x+w]\n",
    "        \n",
    "        # Check the color of the box. Here we're checking the top-left pixel, but you might want to use more pixels for accuracy\n",
    "        color = detect_box_color(patch[0, 0])\n",
    "        \n",
    "        if color:\n",
    "            raw_patch = np.array(raw_img)[y:y+h, x:x+w]\n",
    "            patch_img = Image.fromarray(raw_patch)\n",
    "            \n",
    "            if color == 'red':\n",
    "                patch_img.save(os.path.join(empty_dir, f\"{img_name}_patch_{y}_{x}.jpg\"))\n",
    "            elif color == 'blue':\n",
    "                patch_img.save(os.path.join(occupied_dir, f\"{img_name}_patch_{y}_{x}.jpg\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f4fb294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['18.png', '31.png', '1.png', '21.png', '3.png', '10.png', '24.png', '0.png', '6.png', '15.png', '30.png', '20.png', '4.png', '13.png', '22.png', '11.png', '26.png', '29.png', '2.png', '32.png', '28.png', '12.png', '5.png', '14.png', '8.png', '9.png', '25.png', '27.png', '17.png', '19.png']\n",
      "18.png exists in the directory.\n",
      "31.png exists in the directory.\n",
      "1.png exists in the directory.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# # List all files in the directory\n",
    "# all_files = os.listdir(\"annotated_images/\")\n",
    "# print(all_files)\n",
    "\n",
    "# # Check if a particular file exists\n",
    "# problem_files = ['18.png', '31.png', '1.png']  # ... add all problematic files here\n",
    "# for pf in problem_files:\n",
    "#     if pf in all_files:\n",
    "#         print(f\"{pf} exists in the directory.\")\n",
    "#     else:\n",
    "#         print(f\"{pf} does NOT exist in the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ce26d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty parking spaces detected: 273\n",
      "Number of occupied parking spaces detected: 630\n"
     ]
    }
   ],
   "source": [
    "empty_images = os.listdir(empty_dir)\n",
    "occupied_images = os.listdir(occupied_dir)\n",
    "\n",
    "print(f\"Number of empty parking spaces detected: {len(empty_images)}\")\n",
    "print(f\"Number of occupied parking spaces detected: {len(occupied_images)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2a7463c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 11\u001b[0m \u001b[43mdisplay_random_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43moccupied_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m display_random_sample(empty_dir)\n",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m, in \u001b[0;36mdisplay_random_sample\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m      3\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder, sample)\n\u001b[1;32m      4\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mimshow(img)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(folder)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "def display_random_sample(folder):\n",
    "    sample = random.choice(os.listdir(folder))\n",
    "    img_path = os.path.join(folder, sample)\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.title(folder)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "display_random_sample(occupied_dir)\n",
    "display_random_sample(empty_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "380c70e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw images: ['18.png', '31.png', '1.png', '21.png', '3.png']\n",
      "Annotated images: ['18.png', '31.png', '1.png', '21.png', '3.png']\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw images:\", os.listdir(raw_folder)[:5])\n",
    "print(\"Annotated images:\", os.listdir(annotated_folder)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24112b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# Directories\n",
    "raw_folder = \"raw_images/\"\n",
    "occupied_dir = \"training_data/occupied/\"\n",
    "empty_dir = \"training_data/empty/\"\n",
    "\n",
    "if not os.path.exists(occupied_dir):\n",
    "    os.makedirs(occupied_dir)\n",
    "\n",
    "if not os.path.exists(empty_dir):\n",
    "    os.makedirs(empty_dir)\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"detection-dataset.csv\")\n",
    "\n",
    "def extract_parking_spot(image_path, polygons):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    for polygon_info in polygons:\n",
    "        label = polygon_info['label']\n",
    "        points = polygon_info['points']\n",
    "        \n",
    "        # Draw the polygon to get a mask\n",
    "        mask_img = Image.new('L', img.size, 0)\n",
    "        ImageDraw.Draw(mask_img).polygon(points, outline=1, fill=1)\n",
    "        mask = np.array(mask_img).astype(bool)\n",
    "        \n",
    "        # Extract spot using the mask\n",
    "        spot_img_array = np.zeros_like(img_array)\n",
    "        spot_img_array[mask] = img_array[mask]\n",
    "        spot_img = Image.fromarray(spot_img_array)\n",
    "        \n",
    "        # Save to appropriate folder\n",
    "        if label == \"free_parking_space\":\n",
    "            save_path = os.path.join(empty_dir, f\"{os.path.basename(image_path)}_free_{points[0][0]}_{points[0][1]}.jpg\")\n",
    "        else:  # Assuming only two labels: free_parking_space and not_free_parking_space\n",
    "            save_path = os.path.join(occupied_dir, f\"{os.path.basename(image_path)}_occupied_{points[0][0]}_{points[0][1]}.jpg\")\n",
    "        \n",
    "        spot_img.save(save_path)\n",
    "\n",
    "# Process each image\n",
    "for _, row in df.iterrows():\n",
    "    image_path = os.path.join(raw_folder, row['image_name'])\n",
    "    annotations = ast.literal_eval(row['annotations'])\n",
    "    extract_parking_spot(image_path, annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca57345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
